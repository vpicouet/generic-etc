{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": 0,
        "height": 20,
        "hidden": true,
        "row": 0,
        "width": 12
       }
      }
     }
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     27\u001b[39m instruments, database = load_instruments(sheet_id= \u001b[33m\"\u001b[39m\u001b[33m1Ox0uxEm2TfgzYA6ivkTpU4xrmN5vO5kmnUPdCSt73uU\u001b[39m\u001b[33m\"\u001b[39m, sheet_name= \u001b[33m\"\u001b[39m\u001b[33minstruments.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# instruments, database = load_instruments(sheet_id= \"1Es7_ng3crvjEGhgFtbx-YPBEgj2OBgimHJ3YlzlofVg\", sheet_name= \"instruments.csv\")\u001b[39;00m\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# gaus = lambda x, a, xo, sigma, offset: a ** 2 * np.exp(-np.square((x - xo) / sigma) / 2)+ offset\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# FB = ExposureTimeCalulator(instrument=\"SCWI PERF\",instruments=instruments,database=database)\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# FB = ExposureTimeCalulator(instrument=\"SCWI Matt\",instruments=instruments,database=database)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m FB = ExposureTimeCalulator(instrument=\u001b[33m\"\u001b[39m\u001b[33mSCWI Skipper\u001b[39m\u001b[33m\"\u001b[39m,instruments=instruments,database=database, Δλ=-\u001b[32m10\u001b[39m,Signal=\u001b[32m5e-18\u001b[39m,lambda_stack=\u001b[32m10\u001b[39m, spectra=\u001b[33m\"\u001b[39m\u001b[33m↳ cube_01-resampled_phys\u001b[39m\u001b[33m\"\u001b[39m,\u001b[38;5;28mmin\u001b[39m=\u001b[32m0.54\u001b[39m,\u001b[38;5;28mmax\u001b[39m=\u001b[32m0.85\u001b[39m,interpolation=\u001b[33m\"\u001b[39m\u001b[33mgaussian\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/generic-etc/notebooks/Observation.py:479\u001b[39m, in \u001b[36minitializer.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kargs)\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m    477\u001b[39m         \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, default)\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m func(\u001b[38;5;28mself\u001b[39m, *args, **kargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/generic-etc/notebooks/Observation.py:908\u001b[39m, in \u001b[36mExposureTimeCalulator.__init__\u001b[39m\u001b[34m(self, instruments, database, instrument, x_axis, time_max, SNR_res, spectrograph, **kwargs)\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28mself\u001b[39m.ax0.set_title(title,y=\u001b[32m0.97\u001b[39m,fontsize=\u001b[32m10\u001b[39m)\n\u001b[32m    907\u001b[39m     plt.show(\u001b[38;5;28mself\u001b[39m.fig)  \n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m \u001b[38;5;28mself\u001b[39m.im,\u001b[38;5;28mself\u001b[39m.im_stack = \u001b[38;5;28mself\u001b[39m.new.SimulateFIREBallemCCDImage( Bias=\u001b[33m\"\u001b[39m\u001b[33mAuto\u001b[39m\u001b[33m\"\u001b[39m,  p_sCIC=\u001b[32m0\u001b[39m,  SmearExpDecrement=\u001b[32m50000\u001b[39m,  source=\u001b[33m\"\u001b[39m\u001b[33mBaseline Spectra\u001b[39m\u001b[33m\"\u001b[39m,size=[n1, n2], OSregions=[\u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m(n2,n1)], name=\u001b[33m\"\u001b[39m\u001b[33mAuto\u001b[39m\u001b[33m\"\u001b[39m, spectra=\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m, cube=\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m, n_registers=\u001b[32m604\u001b[39m, save=\u001b[38;5;28;01mFalse\u001b[39;00m, field=\u001b[33m\"\u001b[39m\u001b[33mtargets_F2.csv\u001b[39m\u001b[33m\"\u001b[39m,QElambda=\u001b[38;5;28mself\u001b[39m.QElambda.value,atmlambda=\u001b[38;5;28mself\u001b[39m.QElambda.value,fraction_lya=\u001b[38;5;28mself\u001b[39m.fraction_lya.value, Full_well=\u001b[38;5;28mself\u001b[39m.Full_well, Altitude=\u001b[38;5;28mself\u001b[39m.Altitude, conversion_gain=\u001b[38;5;28mself\u001b[39m.conversion_gain, Throughput_FWHM=\u001b[38;5;28mself\u001b[39m.Throughput_FWHM.value,sky_lines=\u001b[38;5;28mself\u001b[39m.sky_lines.value, Redshift=\u001b[38;5;28mself\u001b[39m.Redshift.value,source_image=\u001b[38;5;28mself\u001b[39m.source_im.value)\n\u001b[32m    909\u001b[39m \u001b[38;5;66;03m# self.im,self.im_stack, self.cube_stack, self.im0, source_im_wo_atm, self.imaADU_stack_only_source, self.imaADU_without_source, self.imaADU_stack_without_source, self.imaADU_source = self.new.SimulateFIREBallemCCDImage( Bias=\"Auto\",  p_sCIC=0,  SmearExpDecrement=50000,  source=\"Baseline Spectra\",size=[n1, n2], OSregions=[0, max(n2,n1)], name=\"Auto\", spectra=\"-\", cube=\"-\", n_registers=604, save=False, field=\"targets_F2.csv\",QElambda=self.QElambda.value,atmlambda=self.QElambda.value,fraction_lya=self.fraction_lya.value, Full_well=self.Full_well, Altitude=self.Altitude, conversion_gain=self.conversion_gain, Throughput_FWHM=self.Throughput_FWHM.value,sky_lines=self.sky_lines.value, Redshift=self.Redshift.value)\u001b[39;00m\n\u001b[32m    911\u001b[39m center = n1/\u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/generic-etc/notebooks/Observation.py:3240\u001b[39m, in \u001b[36mObservation.SimulateFIREBallemCCDImage\u001b[39m\u001b[34m(self, Bias, p_sCIC, SmearExpDecrement, source, size, OSregions, name, spectra, cube, n_registers, save, field, QElambda, atmlambda, fraction_lya, Full_well, conversion_gain, Throughput_FWHM, Altitude, sky_lines, Redshift, IFS, source_image)\u001b[39m\n\u001b[32m   3237\u001b[39m     mask = (\u001b[32m10\u001b[39m*sky_lines[sky_lines.colnames[\u001b[32m0\u001b[39m]]>wavelengths.min()-\u001b[32m10\u001b[39m*\u001b[38;5;28mself\u001b[39m.dispersion) & (\u001b[32m10\u001b[39m*sky_lines[sky_lines.colnames[\u001b[32m0\u001b[39m]]<wavelengths.max()+\u001b[32m10\u001b[39m*\u001b[38;5;28mself\u001b[39m.dispersion)\n\u001b[32m   3238\u001b[39m     sky_lines = sky_lines[mask]\n\u001b[32m-> \u001b[39m\u001b[32m3240\u001b[39m sky = interp1d(\u001b[32m10\u001b[39m*sky_lines[sky_lines.colnames[\u001b[32m0\u001b[39m]],sky_lines[sky_lines.colnames[\u001b[32m1\u001b[39m]])(wavelengths)\n\u001b[32m   3241\u001b[39m \u001b[38;5;28mself\u001b[39m.final_sky_before_convolution = (\u001b[38;5;28mself\u001b[39m.sky/\u001b[38;5;28mself\u001b[39m.exposure_time) * sky * (\u001b[38;5;28mself\u001b[39m.Sky/\u001b[32m1e-16\u001b[39m) \u001b[38;5;66;03m#/np.mean(self.sky)   # \u001b[39;00m\n\u001b[32m   3242\u001b[39m sky_model_interval = \u001b[32m10\u001b[39m * (sky_lines[sky_lines.colnames[\u001b[32m0\u001b[39m]][\u001b[32m1\u001b[39m]-sky_lines[sky_lines.colnames[\u001b[32m0\u001b[39m]][\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/etctest/lib/python3.12/site-packages/scipy/interpolate/_interpolate.py:310\u001b[39m, in \u001b[36minterp1d.__init__\u001b[39m\u001b[34m(self, x, y, kind, axis, copy, bounds_error, fill_value, assume_sorted)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Interpolation goes internally along the first axis\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[38;5;28mself\u001b[39m.y = y\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[38;5;28mself\u001b[39m._y = \u001b[38;5;28mself\u001b[39m._reshape_yi(\u001b[38;5;28mself\u001b[39m.y)\n\u001b[32m    311\u001b[39m \u001b[38;5;28mself\u001b[39m.x = x\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m y, x  \u001b[38;5;66;03m# clean up namespace to prevent misuse; use attributes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/etctest/lib/python3.12/site-packages/scipy/interpolate/_polyint.py:114\u001b[39m, in \u001b[36m_Interpolator1D._reshape_yi\u001b[39m\u001b[34m(self, yi, check)\u001b[39m\n\u001b[32m    111\u001b[39m     ok_shape = (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._y_extra_shape[-\u001b[38;5;28mself\u001b[39m._y_axis:]\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m + (N,) + \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    112\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._y_extra_shape[:-\u001b[38;5;28mself\u001b[39m._y_axis]\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mData must be of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mok_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m yi.reshape((yi.shape[\u001b[32m0\u001b[39m], -\u001b[32m1\u001b[39m))\n",
      "\u001b[31mValueError\u001b[39m: cannot reshape array of size 0 into shape (0,newaxis)"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "%reload_ext autoreload\n",
    "import Observation\n",
    "import glob, os\n",
    "package_path = os.path.dirname(os.path.dirname(os.path.abspath(Observation.__file__)))\n",
    "from Observation import *\n",
    "import re\n",
    "from astropy import units as u\n",
    "import math as mt\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "from astropy.table import Table, hstack, MaskedColumn#, MaskedConstant\n",
    "\n",
    "\n",
    "\n",
    "data_path = os.path.join(package_path, \"data\")\n",
    "data_cube__path = os.path.join(data_path, \"Emission_cube\")\n",
    "if os.path.exists(data_cube__path) is False:\n",
    "    os.makedirs(data_cube__path)\n",
    "for name in [ \"cube_01.fits\", \"lya_cube_merged_with_artificial_source_CU_1pc.fits\", \"CGM_cube.fits\", \"galaxy_disk_cube.fits\", \"galaxy_and_cgm_cube.fits\"]:\n",
    "    if os.path.exists(os.path.join(data_cube__path, \"cube_01.fits\")) is False:\n",
    "        a = download(\n",
    "            url=\"https://nuage.osupytheas.fr/s/fo4AKjoTZ4fBytw/download/\"+name,\n",
    "            file=os.path.join(data_cube__path, name),\n",
    "        )\n",
    "\n",
    "# https://docs.google.com/spreadsheets/d/1Es7_ng3crvjEGhgFtbx-YPBEgj2OBgimHJ3YlzlofVg/edit?gid=2066284077#gid=2066284077\n",
    "instruments, database = load_instruments(sheet_id= \"1Ox0uxEm2TfgzYA6ivkTpU4xrmN5vO5kmnUPdCSt73uU\", sheet_name= \"instruments.csv\")\n",
    "\n",
    "# instruments, database = load_instruments(sheet_id= \"1Es7_ng3crvjEGhgFtbx-YPBEgj2OBgimHJ3YlzlofVg\", sheet_name= \"instruments.csv\")\n",
    "\n",
    "# gaus = lambda x, a, xo, sigma, offset: a ** 2 * np.exp(-np.square((x - xo) / sigma) / 2)+ offset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  when lamda not good for wavelegnth try to show the issue and change the lambda limit of the sepctra\n",
    "\n",
    "# [x]  change resolution also for signal not only for atm\n",
    "# maybe aloow out3 even for slit (just saying that it would take n much more time)\n",
    "\n",
    "# FB = ExposureTimeCalulator(instrument=\"SCWI PERF\",instruments=instruments,database=database)\n",
    "# FB = ExposureTimeCalulator(instrument=\"SCWI Matt\",instruments=instruments,database=database)\n",
    "FB = ExposureTimeCalulator(instrument=\"SCWI PERF\",instruments=instruments,database=database, Δλ=-10,Signal=5e-18,lambda_stack=10, spectra=\"↳ cube_01-resampled_phys\",min=0.54,max=0.85,interpolation=\"gaussian\")\n",
    "# FB = ExposureTimeCalulator(instrument=\"SCWI MIN REQ\",instruments=instruments,database=database)\n",
    "# FB = ExposureTimeCalulator(instrument=\"ASPERA\",instruments=instruments,database=database)\n",
    "# instruments.write(\"/Users/Vincent/Github/fireball2-etc/notebooks/instruments.csv\",overwrite=True)\n",
    "# FB = ExposureTimeCalulator(instrument=\"KCWI blue\",instruments=instruments,database=database)\n",
    "# FB = ExposureTimeCalulator(instru/ment=\"Blue MUSE\",instruments=instruments,database=database)\n",
    "# FB = ExposureTimeCalulator(instrument=\"CETUS\",instruments=instruments,database=database)\n",
    "# FB = ExposureTimeCalulator(instrument=\"JUNO-UVS\",instruments=instruments,database=database)\n",
    "# FB = ExposureTimeCalulator(instrument=\"NISP\",instruments=instruments,database=database)\n",
    "# Hide flux as soon as spectra is selected\n",
    "\n",
    "\n",
    "\n",
    "# be sure that SNR is right for IFS and slits: 1st plot=real SNR (integrating on several fibers/slicers if IFS), 2nd plot=SNR with only one fiber\n",
    "# slitwidth and slit length should have different impact on FB1 (because one dimension impacts resolution and mixes with sky)\n",
    "# clearly with IFS we don't cut flux by the slit base on the PSF at the slit (as it will end in the next slit) - except if the source is << slit?\n",
    "# then we still integrate sky and flux based on slit size. so it is exactly the same impact as binning: \n",
    "# the smaller the fiber, the less we have flux for one fiber but the fllux per arcsec^2 on the image is the same!Is this currently true?\n",
    "\n",
    "# IFS mode does not impact the SNR when slitdidth>>sigma source. But in the other case, we will loose some flux due to cutting\n",
    " # be sure to account well for QE even when throughput curve is given. I guess that I should normalize the throughput curve first and then multiply it by the QE*Atm*Troughput . I think it is fine!\n",
    " # Indeed for now, the counts change a lot when we add QE(%) or not. \n",
    " #account for the TH FWHM, for now it is not taken into account. I think it is fine!\n",
    " #  change the file system so that when we change the instrument we always to see if there is a throughput curve.\n",
    " # Throughput is  not taken into account in the image\n",
    "# TODO understand why SNR is shit for MUSE narrow... because it's done on a pixel size or element resolution (which is small!) WEIRD IT SMALL EVEN WHE BY SOURCE\n",
    "# TODO Ajouter la possibilité d'uploader un spectre...\n",
    "# done TODO for stacking, do not compute N images but just devide the read noise, shot noise etc by sqrt(n)\n",
    "# TODO understand why the emission line evolution is weird.\n",
    "# done TODO error with slicer we print a circle because x=y\n",
    "# DONE TODO be sure to show e-/pix or photons or ADU, etc... Also for the Datacube!\n",
    "# DONE TODO when we go from imager to FB wi loose the name a tab\n",
    "# OK: Remove spectra, throughput(λ), Sky lines, atm(λ), delta(λ)\n",
    "# OK: Reomve Equ width, lambda stack, observed lambda?, Mask PSF (or replace it by sigma ), \n",
    "# OK: always remove Spectrograph design (R, slit dim, dispersion, IFS)\n",
    "# OK: Hide a bunch of parameters in X axis if it is an imager\n",
    "# OK: Resolve all issues and verify plot update\n",
    "# OK replace \"Spectral image\" per \"image\" when imager (name tab)\n",
    "# OK Use the Throughput for integrating the band\n",
    "# OK: use ylog also for the other plot!\n",
    "# OK: reg;er le problemes de log dans el histogramme et les filtes\n",
    "# OK:  comprendre pk on voit pas les filtres pour galex\n",
    "# Find what Image I should show\n",
    "# What should I add? Magnitude? Or even a spectra?\n",
    "# instruments to add: HSC\n",
    "# Different profiles?\n",
    "# add the magnitude somewhere?\n",
    "# Put a simulated image from COSMOS or a simulation (cosmic web?), \n",
    "# Take all the filters from lephare\n",
    "# good TODO passage à LUMOS does not work... \n",
    "# does not work if I begin with that... FB = ExposureTimeCalulator(instrument=\"LUMOS\")\n",
    "# OK TODO last subplot show SB limit per pixel and per resolution element and for 2\n",
    "# TODO ajouter la possibilité d'avoir deux tailles differentes de pixel!! - difficile car il faut changer le type du slider... changer la facon de montrer la slit, etc\n",
    "# TODO verifier que on peut mettre sky line et atm pour tous les instruments (pour l'isntant ca bug)\n",
    "# TODO - trouver un moyen pour les imageurs de mettre n'importe quel filtre...\n",
    "# TODO pour les imageurs avoir la possibilité d'augmenter la taille du filtre pour voir comment ca ameliore les observations\n",
    "# TODO be sure that SNR per spaxel makes sense for IFS!\n",
    "# TODO pb for fiber spectro where the spaxel should be the same on both direction \n",
    "# Slicer does not work for MUSE\n",
    "# the flux change when we change source from cube to not\n",
    "\n",
    "# TODO be sure that the number of pixels is fine! There is a big!! difference between calculating the total flux and dividing by the number of pixels (therefore the PSF grows with number of pixels) and conputing the total flux (which can be hard) and then accountign for the total size and dividing the flux by the number of pixels. \n",
    "# So we need to make sure that computing the total flux and the flux per pixel gives the same result!! for an emission line it is kind of easy but more difficult when it is a spectrum.\n",
    "  \n",
    "# ca marche mais maintrnant il faut eviter que ca diverge avec pixel scale!\n",
    "# de meme quand la dispersion augmente normalement quand elle devient plus important que la largeur de la raie!\n",
    "# TODO should measure the resolution for diffuse source (that taks into account the slit width!)\n",
    "#  understand why there is a factor 1.5 between fit and sigma source\n",
    "\n",
    "# understand why the spectra do not overlap!! juste parce que quand je somme sur plusieurs pixels je diminue l'impact du continuum. donc il faut que je prenne les 10 deniers images de chaque extremité du cubbe, que j'interpole lineairement entre chaque pixel entre les deux, puis que je soustraie cela.\n",
    "# Soit je me laisse une optino soit je commente juste cette ligne ou pas. Normalement ca ne doit jamais rien changer (sauf potentiellement pour le cosmic web qui est entendu en longueur donde)\n",
    "# take only emission from CGM, \n",
    "# subtract the continuum\n",
    "# fabrit perrot interferometer\n",
    "# check spectra in annulus\n",
    "# change size of the stack \n",
    "# adaptative smoothing to implement ? impossible !\n",
    "# TODO quand dispersion diminue vraiment beaucoup, on summ vraiment que sur \n",
    "#TODO  ajouter disperson dans titre car des fois il disparait\n",
    "# weirdly the Throughput_FWHM size in so the same on the plot\n",
    "\n",
    "#exposure time\n",
    "# Spectral_resolution\n",
    "# dispersion\n",
    "\n",
    "\n",
    "# pixel_scale\n",
    "# Slitwidth\n",
    "# EM_gain\n",
    "# Bandwidth\n",
    "#---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaus = lambda  x, a, sigma : a ** 2 * np.exp(-np.square(x / sigma) / 2)\n",
    "# popt, pcov = curve_fit(gaus, rmean[:40],profile[:40], p0=[np.ptp(profile[:40]), 2])\n",
    "# self.self.rp_fit[0].set_data(np.linspace(0,np.max(rmean[:40]),100),gaus(np.linspace(0,np.max(rmean[:40]),100),*popt))\n",
    "\n",
    "# TEST\n",
    "# un dernier probleme avec la slitwidth, ya le sky qui augmente à l'infini, peut etre uniquement opur les IFS? oui en effet!!! et sinon la dispersion toujorus!!\n",
    "# pour les IFS, quand quand la source est plus petite que la fente c'est normale que le SNR max soit quand la fente=source\n",
    "# ndonc dans le caclul du flux total pour les IFS je dois prendre en compte la fente\n",
    "# import os, sys\n",
    "# instrument=\"FIREBall-2 2025\"\n",
    "# # for instrument in instruments.colnames[3::2]:\n",
    "# FB = ExposureTimeCalulator(instrument=instrument)\n",
    "# # time.sleep(2)\n",
    "# SNR_res = \"per Res elem\"\n",
    "# x_axis=\"exposure_time\"\n",
    "# def save(fig, path):\n",
    "#     # create the folders if they do not exist!\n",
    "#     os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "#     fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "# for instrument in [\"SCWI Matt\"]:#instruments.colnames[4:5]: #\"FIREBall-2 2025\"\n",
    "#     FB.instrument.value = instrument  \n",
    "#     for SNR_res in [\"per Res elem\",\"per pix\",\"per Source\"]: \n",
    "#     # for SNR_res in [\"per Res elem\"]: \n",
    "#         FB.SNR_res.value = SNR_res     \n",
    "#         for x_axis in [\"EM_gain\",\"extra_background\",\"CIC_charge\", \"QE\",\"RN\",\"Dark_current\" ,\"cosmic_ray_loss_per_sec\", \"Signal\",'Sky',\"Size_source\",\"Line_width\", \"Atmosphere\",'exposure_time','acquisition_time',\"readout_time\",\"lambda_stack\",  \"wavelength\", 'Collecting_area',\"pixel_scale\",\"Throughput\",\"PSF_RMS_mask\",\"PSF_RMS_det\",\"Spectral_resolution\",\"Slitwidth\",\"Slitlength\",\"dispersion\"]:\n",
    "#         # for x_axis in [\"Size_source\",\"dispersion\", \"pixel_scale\",\"Slitwidth\"]:\n",
    "#             print(x_axis)\n",
    "#             FB.x_axis.value = x_axis\n",
    "#             # time.sleep(1)\n",
    "#             save(FB.fig, \"/Users/Vincent/Nextcloud/LAM_new_account/Work/ETC/instruments2/%s/%s_%s_matt.png\"%(instrument.replace(\" \",\"_\"),x_axis.replace(\" \",\"_\"),SNR_res.replace(\" \",\"_\")))\n",
    "#             FB.test.value=False\n",
    "#             save(FB.fig, \"/Users/Vincent/Nextcloud/LAM_new_account/Work/ETC/instruments2/%s/%s_%s.png\"%(instrument.replace(\" \",\"_\"),x_axis.replace(\" \",\"_\"),SNR_res.replace(\" \",\"_\")))\n",
    "#             FB.test.value=True\n",
    "\n",
    "# import os, sys\n",
    "# instrument=\"FIREBall-2 2025\"\n",
    "# # for instrument in instruments.colnames[3::2]:\n",
    "# FB = ExposureTimeCalulator(instrument=instrument)\n",
    "# # time.sleep(2)\n",
    "# SNR_res = \"per Res elem\"\n",
    "# x_axis=\"exposure_time\"\n",
    "# def save(fig, path):\n",
    "#     # create the folders if they do not exist!\n",
    "#     os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "#     fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "# for instrument in instruments.colnames[4:]:\n",
    "#     FB.instrument.value = instrument  \n",
    "#     for SNR_res in [\"per Res elem\",\"per pix\",\"per Source\"]: \n",
    "#         FB.SNR_res.value = SNR_res     \n",
    "#         for x_axis in [\"QE\",\"RN\",\"Dark_current\" ,\"cosmic_ray_loss_per_sec\", \"Signal\",\"Redshift\",'Sky',\"PSF_source\",\"Line_width\", \"Atmosphere\",'exposure_time','acquisition_time',\"readout_time\",\"lambda_stack\",  \"wavelength\", 'Collecting_area',\"pixel_scale\",\"Throughput\",\"PSF_RMS_mask\",\"PSF_RMS_det\",\"Spectral_resolution\",\"Slitwidth\",\"Slitlength\",\"dispersion\"]:\n",
    "#             FB.x_axis.value = x_axis\n",
    "#             # time.sleep(1)\n",
    "#             save(FB.fig, \"/tmp/%s/%s/%s.png\"%(instrument.replace(\" \",\"_\"),SNR_res.replace(\" \",\"_\"),x_axis.replace(\" \",\"_\")))\n",
    "       \n",
    "# FB.output_tabs.selected_index = 1\n",
    "# for instrument in instruments.colnames[3:]:\n",
    "#     for flux in [1e-17,1e-16,1e-15,1e-14]:\n",
    "#         FB.Signal.value = flux\n",
    "#         save(FB.fig2, \"/tmp/%s/%s/Flux_%s.png\"%(instrument.replace(\" \",\"_\"),\"Image\",flux))\n",
    "#     FB.instrument.value = instrument     \n",
    "#     # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f54e7ecca8429e881c6b968af69b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), VBox(children=(HBox(children=(Dropdown(description='Instrument', index=3, layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FB = ExposureTimeCalulator(instrument=\"SCWI SPEC\",instruments=instruments,database=database, Δλ=-10,Signal=5e-18,lambda_stack=10,min=0.54,max=0.85,interpolation=\"gaussian\") #, spectra=\"↳ cube_01-resampled_phys\"\n",
    "\n",
    "FB = ExposureTimeCalulator(instrument=\"SCWI SPEC\",instruments=instruments,database=database,Signal=5e-17,lambda_stack=10,min=0.54,max=0.85,interpolation=\"gaussian\") #, spectra=\"↳ cube_01-resampled_phys\"  , Δλ=-1\n",
    "\n",
    "\n",
    "# def download(url, file=\"\"):\n",
    "#     \"\"\"Download a file\n",
    "#     \"\"\"\n",
    "#     from tqdm import tqdm  # , tqdm_gui\n",
    "#     import requests\n",
    "\n",
    "#     try:\n",
    "#         response = requests.get(url, stream=True)\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         verboseprint(e)\n",
    "#         return False\n",
    "#     else:\n",
    "#         total_size_in_bytes = int(response.headers.get(\"content-length\", 0))\n",
    "#         block_size = 1024  # 1 Kibibyte\n",
    "#         progress_bar = tqdm(\n",
    "#             total=0.95 * total_size_in_bytes, unit=\"iB\", unit_scale=True\n",
    "#         )\n",
    "#         with open(file, \"wb\") as file:\n",
    "#             for data in response.iter_content(block_size):\n",
    "#                 progress_bar.update(len(data))\n",
    "#                 file.write(data)\n",
    "#         # progress_bar.close()\n",
    "#         # tqdm_gui.close(progress_bar)\n",
    "#         # progress_bar.display()\n",
    "#         # progress_bar.plt.close(progress_bar.fig)\n",
    "#         # plt.show(block=False)\n",
    "#         # plt.close('all')\n",
    "#         # plt.close(progress_bar.fig)\n",
    "#         if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "#             verboseprint(\"ERROR, something went wrong\")\n",
    "#             return False\n",
    "#         else:\n",
    "#             return True\n",
    "\n",
    "\n",
    "\n",
    "#exposure time\n",
    "# Spectral_resolution\n",
    "# dispersion\n",
    "# slice width\n",
    "\n",
    "\n",
    "# pixel_scale\n",
    "# Slitwidth\n",
    "# EM_gain\n",
    "# Bandwidth\n",
    "#---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371100c1cfec48f3bf45882553553867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), VBox(children=(HBox(children=(Dropdown(description='Instrument', layout=Layout(width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # FIREBall = ExposureTimeCalulator(instrument=\"FIREBall-2 2023\")\n",
    "# FIREBall.counting_mode\n",
    "# from Observation import *\n",
    "# Observation(exposure_time=np.linspace(50,1500,50),RN=50,smearing=0.2,counting_mode=True,plot_=False).compute_optimal_threshold(plot_=True,flux=0.03,size= (int(1e3),int(1e3)))\n",
    "FB = ExposureTimeCalulator(instrument=\"SCWI EMCCD\",instruments=instruments,database=database, Δλ=-10,Signal=5e-18,lambda_stack=10, spectra=\"↳ cube_01-resampled_phys\",min=0.54,max=0.85,interpolation=\"gaussian\",sky_lines=False,atmlambda=False,QElambda=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34a743250504f98aa67958db32a2742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), VBox(children=(HBox(children=(Dropdown(description='Instrument', index=2, layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FB = ExposureTimeCalulator(instrument=\"SCWI MCP\",instruments=instruments,database=database, Δλ=-10,Signal=5e-18,lambda_stack=10, spectra=\"↳ cube_01-resampled_phys\",min=0.54,max=0.85,interpolation=\"gaussian\",sky_lines=False,atmlambda=False,QElambda=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2794052330c7457daf5ba6295e047cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), VBox(children=(HBox(children=(Dropdown(description='Instrument', index=1, layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FB = ExposureTimeCalulator(instrument=\"SCWI Skipper\",instruments=instruments,database=database, Δλ=-10,Signal=5e-18,lambda_stack=10, spectra=\"↳ cube_01-resampled_phys\",min=0.54,max=0.85,interpolation=\"gaussian\",sky_lines=False,atmlambda=False,QElambda=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_spiral_galaxy(amplitude,redshift, platescale, PSF_RMS,size_kpc):\n",
    "#     \"\"\"\n",
    "#     Generates a simulated galaxy image of defined size and PSF.\n",
    "    \n",
    "#     Parameters:\n",
    "#     redshift (float): Redshift of the galaxy.\n",
    "#     platescale (float): Size of one pixel in arcsec/pix.\n",
    "#     PSF_RMS (float): RMS size of the PSF in arcsec.\n",
    "    \n",
    "#     Returns:\n",
    "#     np.ndarray: Simulated and convolved 2D galaxy image.\n",
    "#     \"\"\"\n",
    "#     # size_kpc = 10.0  # Physical size of the galaxy in kpc\n",
    "#     intensity = 0.4\n",
    "#     final_image_size = [500,100]  # Number of pixels per side of the output image\n",
    "#     angular_size_arcsec = size_kpc / cosmo.kpc_proper_per_arcmin(redshift).to(u.kpc / u.arcsec).value\n",
    "#     angular_size_pix = angular_size_arcsec / platescale\n",
    "\n",
    "#     # field_of_view_arcsec = \n",
    "#     x = np.linspace(-platescale * final_image_size[0] / 2, platescale * final_image_size[0] / 2, final_image_size[0])\n",
    "#     y = np.linspace(-platescale * final_image_size[1] / 2, platescale * final_image_size[1] / 2, final_image_size[1])\n",
    "#     xx, yy = np.meshgrid(x, y)\n",
    "#     r = np.sqrt(xx**2 + yy**2)\n",
    "#     theta = np.arctan2(yy, xx)\n",
    "    \n",
    "#     core = np.exp(-r**2 / (2 * (angular_size_arcsec / 5 / 2.355)**2))\n",
    "#     spiral = np.exp(-r**2 / (2 * (angular_size_arcsec / 2.355)**2)) * (1 + intensity * np.sin(2 * theta + r * 20 / angular_size_arcsec))\n",
    "#     galaxy = core + spiral\n",
    "\n",
    "#     # Normalize the galaxy to conserve total energy\n",
    "#     galaxy_sum_initial = np.max(galaxy)*100\n",
    "#     galaxy *= amplitude /galaxy_sum_initial  # Normalize so that the sum is 1\n",
    "#     galaxy *= size_kpc * size_kpc  # Scale to maintain the total energy constant\n",
    "\n",
    "#     PSF_RMS_pix = np.sqrt(PSF_RMS**2 + 0.05**2) / platescale\n",
    "#     galaxy_convolved = gaussian_filter(galaxy, PSF_RMS_pix)\n",
    "\n",
    "#     return galaxy_convolved\n",
    "\n",
    "# # plt.figure();plt.imshow(generate_spiral_galaxy(amplitude=FB.flux, redshift=0.001, platescale=FB.pixel_scale.value, PSF_RMS=FB.PSF_RMS_det, size_kpc=12));plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (os.path.exists(\"../data/Instruments/%s/Sky_emission_lines.csv\"%(FB.instrument.replace(\" \",\"_\"))) )\n",
    "# print(1)\n",
    "# a = Table.read(\"Sky_emission_lines/spectra.csv\")\n",
    "# fig = plt.figure(figsize=(15,3))\n",
    "# plt.loglog(a[\"# wavelength\"]/10000,a[\"emission_lines\"],\":\",c=\"k\",alpha=0.8,lw=0.2)\n",
    "# plt.ylim(ymin=1e-2)\n",
    "# plt.xlabel(\"Wavelength (microns)\")\n",
    "# plt.ylabel(\"Sky flux in \\n1E-16 erg/[s A cm**2 arcs**2]\")\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "# # sky model\n",
    "# # sky observing mode\n",
    "# # different modes\n",
    "# # seing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data = \"\"\"\n",
    "# -27.09946824154065,   0.5656884604299096\n",
    "# -17.763888116112412, 1.1948670570576576\n",
    "# -9.97430231541449,   2.43555498224965\n",
    "# -0.6426964684559948, 4.964508843492912\n",
    "# 8.68096082156302, 9.423816134476512\n",
    "# 21.104555317982204, 20.626853767154984\n",
    "# 38.17805562400167, 55.90139946933155\n",
    "# 59.885564625742404, 162.6822634252464\n",
    "# 81.57717651360417, 410.58403825329606\n",
    "# 112.55270290678749, 1377.7653482012001\n",
    "# -0.539365228242616, 12.529627053302825\n",
    "# -0.45987965884773985, 25.53974135879882\n",
    "# -0.3883426463923456, 48.48049107675056\n",
    "# -0.3009085200579875, 106.1141246529154\n",
    "# -0.14988593820771712, 410.5840382532977\n",
    "# -0.08629748269180482, 725.8129995108268\n",
    "# \"\"\"\n",
    "\n",
    "# # Split the data into lines and then into individual values\n",
    "# lines = data.strip().split('\\n')\n",
    "# Temp_c = []\n",
    "# Pressure_mbar = []\n",
    "\n",
    "# for line in lines:\n",
    "#     temp, pressure = map(float, line.split(','))\n",
    "#     Temp_c.append(temp)\n",
    "#     Pressure_mbar.append(pressure)\n",
    "\n",
    "# # Convert lists to numpy arrays\n",
    "# Temp_c = np.array(Temp_c)\n",
    "# Pressure_mbar = np.array(Pressure_mbar)\n",
    "\n",
    "# print(\"Temp_c:\", Temp_c)\n",
    "# print(\"Pressure_mbar:\", Pressure_mbar)\n",
    "\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Définition de la fonction de pression de vapeur selon la formule de Buck\n",
    "# def buck_pressure(T):\n",
    "#     \"\"\"Calcule la pression de vapeur d'eau en kPa pour une température donnée (T en °C).\"\"\"\n",
    "#     return 0.61121 * np.exp((18.678 - (T / 234.5)) * (T / (257.14 + T)))\n",
    "\n",
    "# # Définition des plages de température\n",
    "# T_range = np.linspace(-10, 15, 200)  # Température de -10°C à 15°C\n",
    "\n",
    "# # Calcul des pressions en mbar (1 kPa = 10 mbar)\n",
    "# P_range = buck_pressure(T_range) * 10\n",
    "\n",
    "# # Création du graphique\n",
    "# fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# # Tracé de la courbe\n",
    "# ax.plot(T_range, P_range)#, label=\"Pression de vapeur de l'eau (Buck)\", color=\"blue\")\n",
    "\n",
    "# # Fill between to show the 3 phases of water\n",
    "# ax.fill_between(T_range, 0, P_range, where=(T_range <= 100), color='lightcoral', alpha=0.1, label=\"Solid (Ice)\")\n",
    "# # ax.fill_between(T_range, 0, P_range, where=(T_range > 0), color='lightgreen', alpha=0.3, label=\"Liquid (Water)\")\n",
    "# ax.fill_between(T_range, P_range, 18, where=(T_range <= 0), color='lightblue', alpha=0.1, label=\"Vapor (Steam)\")\n",
    "# ax.fill_between(T_range, P_range, 18, where=(T_range > 0), color='lightyellow', alpha=0.1, label=\"Vapor (Steam)\")\n",
    "\n",
    "# # Ajout des annotations importantes\n",
    "# # ax.axhline(y=7.5, color=\"deepskyblue\", linestyle=\"--\", label=\"Pression nominale du Dewar (~7-8 mbar)\")\n",
    "# # ax.axvline(x=2.4, color=\"blue\", linestyle=\"--\", label=\"Température d'évaporation nominale (~2.4°C)\")\n",
    "\n",
    "# # Zone critique de gel de l'eau (remplissage gris)\n",
    "# # ax.fill_between(T_range, 0, 4, color='gray', alpha=0.3, label=\"Zone critique de gel de l'eau\")\n",
    "\n",
    "# # Ajout de texte explicatif\n",
    "# # ax.annotate(\"Évolution de T/P en vol\", xy=(5, 10), xytext=(7, 14),\n",
    "# #             arrowprops=dict(facecolor='black', arrowstyle=\"->\"), fontsize=10)\n",
    "\n",
    "# # Labels et titre\n",
    "# ax.set_xlabel(\"Temperature (°C)\")\n",
    "# ax.set_ylabel(\"Pressure (hPa)\")\n",
    "# ax.set_title(\"Temperature Dependence - Evaporation Pressure of Water\")\n",
    "\n",
    "# # Légende\n",
    "# # ax.legend()\n",
    "# plt.xlim(-11,16)\n",
    "# plt.ylim(2,18)\n",
    "# # plt.yscale(\"log\")\n",
    "# # plt.plot(Temp_c,Pressure_mbar)\n",
    "# # Affichage du graphique\n",
    "# plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- # <center>FIREBall-2 SNR calculator </center>\n",
    "\n",
    "### Explanation\n",
    "- Gives the estimated signal-to-noise ratio for an extended source on a resolution element\n",
    "- **Variables:** Source's flux, sky, aquisition time, exposure time, EM gain, dark current, CIC, readnoise, readout time, thresholding, smearing exponential length and temperature if you check it (based on a first rough evolution of smearing and dark current with temperature, therefore changing the temperature will change smearing and dark accordingly.)\n",
    "- **Fixed Values:** QE = 45%, resolution element=57 mu, pixel_size = 13 mu, throughput = 13%, atmosphere transmission = 50%\n",
    "- **Outputs:** In the top pannel, the noise of the different sources (Signal, Dark, Sky, CIC, RN) is given in e- per resolution element per N frames on the total acquisition time. The middle pannel we give the average e-/pix value for each component (before stacking). We give the relative fraction of all sources of noise and the resulting SNR. When thresholding is applied, the smearing can be changed as it will impact the position of the threshold that optimizes the SNR. For this optimal threshold, the fraction of signal and readnoise kept (above the threshold) is given.\n",
    "- **Caution:**  it appears that for EMCCDs the dependencies are pretty complex/non-linear. In particular, the lack of models on the impact of amplification, thresholding, and register clearing... combined with smearing on the final SNR makes risky the fact of relying only on modeling to choose the optimal temperature/gain/etc. That's why I suggest an [end-to-end test](https://docs.google.com/document/d/1SpiEK8MBmYduKUFvWmnTOfkfsX4VWs6JMF5-YJKDELo/edit?usp=sharing) validating this: \n",
    "\n",
    "\n",
    "### Analysis\n",
    "- **Smearing:** At -120C, the low device's CTE smears the pixels' counts and then lowers the effective gain. This lowering factor is huge (>2) for a smearing length of 1.5, but is much smaller for a smearing length of 0.7 (~1.2). \n",
    "It seems that we already had a comparabale 0.7 smearing length with previous controller at 10MHz (tests February 7th and 8th 2019) at same EMgain (1600) and temperature (-95C). Which might mean that the 1MHz reading does not decrease significantly the smearing. **With the current (2022) smearing length, thresholding does not increase the SNR!! If we manage to invert the smearing, even if it doubles the readnoise, we could recover most of the thresholding efficiency.**\n",
    "- **Photon-counting:** The thresholding effect can be misleading as it depends on Flux, EMgain, RN, smearing and noise($\\sigma_{CIC}^2 + \\sigma_{DC}^2+ \\sigma_{SKY}^2$). But actually it depends mostly on the ratio $\\frac{G_{EM,eff}}{RN}$. For a ratio >> 10 the thresholding is efficient. As stated above for a smearing length of 0.7, EMgain and effective_gain are close. A consequence of that, is that at the EMgains we use ($\\sim1600$) and smearing $\\sim 0.7$, the thresholding is almost as efficient with RN=50 and RN=107 as the ratio $\\frac{G_{EM,eff}}{RN}$ stays >>10. This was not the case in 2018 when the smearing length was 1.5. This is why in photon counting mode, you will see a very small impact of read noise change.\n",
    "- **Reading frequency tradeoff:** Based on above, the change from 10MHz to 1MHz as minor consequences on the total SNR.\n",
    "    - In photon counting mode and with low smearing, the decrease of the RN has quasi no effect (~1%) on the SNR\n",
    "    - The transition from 1.4 to 3sec readout would mean a loss of SNR of ~2%, transition to 10sec about ~10% \n",
    "    - Therefore the real critical point is the possible need to add or not a shutter above the tank with the 1MHz controller as it will complexify guidance\n",
    "- **Temperature Tradeoff:** Conclusion depends on the definition of SNR on thresholded images (see below): In both cases, the SNR decreases with smearing but in one case smearing has more important impact and compensate  dark current giving rise to an optimal temperature. Though, the fact that we will never get rid of dark current while we could actually manage to inverse the smearing could suggest staying at low temperature (-120 to -110).\n",
    "\n",
    " \n",
    "  \n",
    "  \n",
    "|             **Parameters**             |          **2022 1Mhz controller**           | **Values 2018** |\n",
    "| :------------------------------------: | :-----------------------------------------: | :-------------: |\n",
    "|          **Temperature (C)**           |                     -95                     |      -115       |\n",
    "|       **Conversion gain ADU/e-**       |                    1/4.5                    |      0.53       |\n",
    "|           **Read noise e-**            |            50 -> 60 longer cable            |       107       |\n",
    "|         **pCIC e− /pix/frame**         |                    0.003                    |      0.004      |\n",
    "|         **sCIC e− /pix/frame**         |                   ~0.002                    |     ~0.002      |\n",
    "|  **semi-amplified CIC e− /pix/frame**  |                    ~0.02                    |     ~0.03-4     |\n",
    "|           **EM gain  e-/e-**           |          O                    2000          |      1400       |\n",
    "|   **Smearing exponent. length pix**    |              L~0.6 ± 0.1  pix               |   L~1.5 ± 0.1   |\n",
    "|       **Dark current e− /pix/h**       |                   ~2±0.5                    |   0.5 ± 0.03    |\n",
    "| **Cosmetics % pixels bottom detector** |                     ~2%                     |   <<1% (TBD)    |\n",
    "|         **Exposure time sec**          |                     50                      |       50        |\n",
    "|          **Readout time sec**          | ~10 (all), ~3(physical) +2 better clearance |      ~1.4       |\n",
    "\n",
    "\n",
    "<!-- \n",
    "### Need to add\n",
    "- Predictions for point source, sources on several resolution element, stack of galaxies\n",
    " -->\n",
    "\n",
    "<!-- Based on the 2019 and 2022 images the consequences of a 20 degrees increase is important. With the first approximations, the increase of the dark current combined with the decrease of the smearing length might lead to a 5% SNR increase in counting mode (+sharper PSF). Though, for now, the major consequence of the temperature increase seems to be the high fraction of cosmetics on the lower part of the image. A significant fraction could be corrected for with appropriated software but the fraction can become extremely high and prevent good correction (needs further implementation). This is not taken into account in this model. Decreasing the tempetrature to -100C (TBD) might be a good trade off (in 2019 we had 0.8 smearing at -95C and EMgain=1600). For very bright objects the shot noise becomes dominant and then the impact of dark current is smaller so the SNR peaks at higher temps (80).\n",
    "  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "<!-- \n",
    "## Thresholding analysis\n",
    "The threshold is computed by optimizing the SNR:\n",
    "\n",
    "$$ SNR_1(T) = F_{True,pos}(T)\\frac{S \\times F_{e^->0,ADU>T}}{\\sqrt{ F_{e^->0,ADU>T} \\times(S + \\sigma_{CIC}^2 + \\sigma_{DC}^2+ \\sigma_{SKY}^2)  + F_{e^-=0,ADU>T} \\frac{\\sigma_{RN}^2}{Gain} }} \n",
    "\\sim F_{True,pos}(T) \\frac{S \\sqrt{ F_{e^->0,ADU>T}}}{\\sqrt{S + \\sigma_{CIC}^2 + \\sigma_{DC}^2+ \\sigma_{SKY}^2 }}$$\n",
    "\n",
    "\n",
    "\n",
    "with:\n",
    "- $\\sigma_{RN}^2=\\frac{RN}{G_{EM}} \\times \\frac{\\sum RN[RN>T]}{\\sum RN} = \\frac{RN}{EMgain}  \\times \\%pix_{e^-=0}^{ADU>T}$: ie 60e-/2000 x the fraction of pixels above the threshold which dit not receive any photo-electrons \n",
    "- $ F_{e^->0,ADU>T}$ :  fraction of pixels above the threshold which received more than 0 electons\n",
    "- $ F_{e^-=0,ADU>T}$ :  fraction of pixels above the threshold which did not receive any electron\n",
    "- $F_{True,pos} = \\frac{F_{e^->0,ADU>T}}{F_{ADU>T}} $ : the fraction of true positives = the fraction of pixels above the threshold which received more than 0 electons. This uncertainty term is not in the final SNR formula as it converges towards ~1 after stacking as the average pixel value will converge towards the real number of incoming photo-electrons\n",
    "\n",
    "The thresholding depends on 5 factors:\n",
    "- **The gain**: the higher the gain the easier it is to differentiate pixels who received a photo-electron and those which did not\n",
    "- **The read noise**: the lower the RN the easier it is to differentiate pixels who received a photo-electron and those which did not\n",
    "- **The low CTE** smears the charges, from pixels who did receive a photo-electron to pixel who did not and lower the effective gain $G_{EM,eff}$\n",
    "- **The signal**: because thresholding only allows to recover 0 and 1, thresholding is only efficient at flux <<1e-/exp \n",
    "- **The additional noise**: $\\sigma = \\sigma_{CIC}^2 + \\sigma_{DC}^2+ \\sigma_{SKY}^2$ has relatively small impact on the impact of the thresholding\n",
    "\n",
    "**At the end, the thresholding impact is:**\n",
    "- Highly non linear, many things to learn\n",
    "- The efficiency of the thresholding depends mostly of the ratio $\\frac{G_{EM,eff}}{RN}$, which extremely impacted by the smearing.\n",
    "- The thresholding SNR gain (SNR$_{threshold}$/SNR$_{analogic}$) lies within $[0,\\sqrt{2}]$. Condditions are pretty stricts to get som thresholding efficiency and smearing makes the upper bound falls dramatically. \n",
    "- Therefore if might not worth it to loose SNR in order to be in these very conditions as we will loose it anyway in the final budget.\n",
    "- The thresholding SNR gain seems less impacted by read noise. Which means that if we manage to do some (linear?) inversion of the smearing which increases the noise, it might still increase the thresholding gain above 1. \n",
    "- The only real game changer in terms of SNR is the smearing \n",
    "- **Fraction kept (photo-electrons above threshold)**\n",
    "    - Important dependance on smearing and flux, less important one on gain and read noise.\n",
    "    - At low smearing the bigger the ratio gain/ron the higher the fraction of charges kept.\n",
    "    - Evolution with smearing is dramatic, higher gain does not help much, lower RN helps\n",
    "    - Fraction increase with flux \n",
    "- **Fraction fake detections (0e- pixels above threshold)**\n",
    "    - Increases importantly with smearing\n",
    "    - does not depend much on read noise (small positive correlation)\n",
    "    - decreases with gain\n",
    "    - Increases as Flux increase. Not sure to understand why... Maybe because the number of pixels with 0 photo-e- cecreases \n",
    "- **Thresholding SNR gain**\n",
    "    - Thresholding is efficient only if >1\n",
    "    - Dramatically decreases with smearing (No interest of thrsholding above smearing legth of 0.6)\n",
    "    - Increases with gain and decreases with read noise if no smearing\n",
    "    - if smearing, the read noise has no impact.\n",
    "    - Increases with flux\n",
    "- **Threshold**\n",
    "    - increase extremely with smearing\n",
    "    - Without smearing, poor dependance on gain and readnoise\n",
    "    - If smearing, increases as readnoise decreases\n",
    "    - If smearing: Increasing with gain!\n",
    "    - Increases with flux\n",
    "\n",
    " -->\n",
    "\n",
    "<!-- \n",
    "\n",
    "|   **Thresholding dependancy table**                   | **Smearing <br />  ( 0 - 2 )** | **Read noise  <br /> ( 30 - 120 )** | **Gain  <br /> ( 800 - 2500 )** | **Flux <br /> ( 0.01 - 1.5 )** |\n",
    "|:--------------------:|:------------------:|:-----------------------:|:-------------------:|:------------------:|\n",
    "|     **Photo-electron Fraction kept**    |    --- <br /> 92% - 66%    |       -  <br /> 72% - 71%       |     .   <br /> 72% - 71%    |     +  <br /> 75% - 76%    |\n",
    "| **RN fraction kept** |  +++  <br /> 0.6% - 12.4%  |       +  <br /> 0.7% - 1%       |    -  <br /> 1.1% - 0.5%    |    ++?  <br /> 0.3% - 3%   |\n",
    "|     **Threshold**    |   +++  <br /> 3 σ - 11 σ   |      --  <br /> 18 σ - 5 σ      |     + <br />  5 σ - 16 σ    |    +? <br />  8 σ - 13 σ    |\n",
    "|        **Thresholding SNR gain**       |     --- <br />  1.3 - 0.6   |        --  <br /> 1.35 - 1.22        |      +  <br /> 1.13 - 1.18      |      ++  <br /> 1.16 - 1.21     |\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 2,
      "defaultCellHeight": 400,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "etctest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
